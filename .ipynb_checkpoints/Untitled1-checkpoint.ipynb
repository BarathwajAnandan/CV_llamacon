{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0fe243-cb15-4306-a275-a52569d6a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-04 15:03:56.644719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746371036.664965  136955 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746371036.671410  136955 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Loading checkpoint shards: 100%|██████████| 50/50 [00:41<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Llama4ForConditionalGeneration\n",
    "import torch\n",
    "from transformers import AutoConfig\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5,6,7'\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"meta-llama/Llama-4-Scout-17B-16E-Instruct\",\n",
    "    output_router_logits=True,         # enable router-softmax output\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"meta-llama/Llama-4-Scout-17B-16E-Instruct\")\n",
    "model = Llama4ForConditionalGeneration.from_pretrained(\n",
    "    \"meta-llama/Llama-4-Scout-17B-16E-Instruct\",\n",
    "    config=config,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed678d0-c95f-4ab7-890f-cf5fb9a8340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a hook to capture router probabilities\n",
    "# router_probs = []\n",
    "\n",
    "# def hook_fn(module, input, output):\n",
    "#     # Print information about input and output\n",
    "#     input_shape = [i.shape if isinstance(i, torch.Tensor) else type(i) for i in input]\n",
    "#     # print(f\"Router input shape: {input_shape}\")\n",
    "#     # print(\"output\", output)\n",
    "#     # Check if output is a tensor or has special attributes\n",
    "#     if isinstance(output, torch.Tensor):\n",
    "        \n",
    "#         # print(f\"Router output shape: {output.shape}\")\n",
    "#         # Only capture based on actual sequence length\n",
    "#         seq_len = input[0].shape[1] if isinstance(input[0], torch.Tensor) else 0\n",
    "#         if seq_len > 0 and seq_len < output.shape[0]:\n",
    "#             output_slice = output[:seq_len]\n",
    "#         #     router_probs.append(output_slice.detach().cpu())\n",
    "#         else:\n",
    "#             router_probs.append(output.detach().cpu())\n",
    "#     else:\n",
    "#         print(f\"Router output type: {type(output)}\")\n",
    "#         print(output)\n",
    "#         if hasattr(output, 'router_probs'):\n",
    "#             router_probs.append(output.router_probs.detach().cpu())\n",
    "\n",
    "# # Register hooks on MoE layers\n",
    "# for name, module in model.named_modules():\n",
    "#     # print(name, type(module))\n",
    "#     if \"router\" in name.lower():\n",
    "#         # print(\"module names with router in it : \", name.lower())\n",
    "#         module.register_forward_hook(hook_fn)\n",
    "\n",
    "# # Process some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc04d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook_count = 0\n",
    "# # Register hooks on MoE layers\n",
    "# for i, (name, module) in enumerate(model.named_modules()):\n",
    "#     if \"router\" in name.lower():\n",
    "#         # print(\"Registering hook on:\", name, type(module))\n",
    "#         module.register_forward_hook(hook_fn)\n",
    "#         hook_count += 1\n",
    "# print(f\"Total hooks registered: {hook_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ec5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_probs = {}\n",
    "def make_hook(layer_name):\n",
    "    def hook_fn(module, input, output):\n",
    "        # Determine actual sequence length from input\n",
    "        seq_len = input[0].shape[1] if isinstance(input[0], torch.Tensor) else 0\n",
    "\n",
    "        # Handle tensor output\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            out = output[:seq_len] if seq_len > 0 and seq_len < output.shape[0] else output\n",
    "            out = out.detach().cpu()\n",
    "        # Handle objects with 'router_probs' attribute\n",
    "        elif hasattr(output, 'router_probs'):\n",
    "            out = output.router_probs.detach().cpu()\n",
    "        else:\n",
    "            print(f\"[{layer_name}] Unknown output type: {type(output)}\")\n",
    "            out = None\n",
    "\n",
    "        # Store in dictionary if valid\n",
    "        if out is not None:\n",
    "            if layer_name not in router_probs:\n",
    "                router_probs[layer_name] = []\n",
    "            router_probs[layer_name].append(out)\n",
    "\n",
    "    return hook_fn\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if \"router\" in name.lower():\n",
    "        module.register_forward_hook(make_hook(name))\n",
    "        # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad0de8c-478a-441d-9b15-e8dedb6e128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 17\n",
      "Number of output tokens: 2\n",
      "Processing time: 0.0022 seconds\n",
      "Generation time: 0.2129 seconds\n",
      "Decoding time: 0.0002 seconds\n",
      "Total time: 0.2156 seconds\n",
      "\n",
      "Generated text:\n",
      "assistant\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Write a python code to calculate perimeter of a rectangle\" },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Start timing\n",
    "start_total = time.time()\n",
    "\n",
    "# Time the processing part\n",
    "start_process = time.time()\n",
    "tokenized = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    ")\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "process_time = time.time() - start_process\n",
    "num_input_tokens = inputs[\"input_ids\"].shape[1]\n",
    "print(f\"Number of input tokens: {num_input_tokens}\")\n",
    "# Time the generation part\n",
    "start_generate = time.time()\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    return_dict_in_generate=True,\n",
    ")\n",
    "generate_time = time.time() - start_generate\n",
    "\n",
    "# Time the decoding part\n",
    "start_decode = time.time()\n",
    "generated_tokens = outputs.sequences[0, inputs.input_ids.shape[1]:]\n",
    "decoded_text = processor.decode(generated_tokens, skip_special_tokens=True)\n",
    "decode_time = time.time() - start_decode\n",
    "\n",
    "# Calculate total time\n",
    "total_time = time.time() - start_total\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of output tokens: {len(generated_tokens)}\")\n",
    "print(f\"Processing time: {process_time:.4f} seconds\")\n",
    "print(f\"Generation time: {generate_time:.4f} seconds\")\n",
    "print(f\"Decoding time: {decode_time:.4f} seconds\")\n",
    "print(f\"Total time: {total_time:.4f} seconds\")\n",
    "print(\"\\nGenerated text:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ca544-9b31-4597-965b-2b50f8a67c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "num_experts = 16\n",
    "load = torch.zeros(num_experts)\n",
    "importance = torch.zeros(num_experts)\n",
    "hook_count = 48\n",
    "num_layers = hook_count\n",
    "\n",
    "all_loads = []\n",
    "all_importance = []\n",
    "for layer_name in router_probs.keys():\n",
    "    router_outputs = router_probs[layer_name]\n",
    "    num_experts = router_outputs[0].shape[-1]  # Assuming consistent expert count\n",
    "    load = torch.zeros(num_experts, dtype=torch.int32)\n",
    "    importance = torch.zeros(num_experts, dtype=torch.float32)\n",
    "    # print(f\"Tokens processed: {len(router_outputs) // num_layers}\")\n",
    "    for probs in router_outputs:\n",
    "        probs = F.softmax(probs, dim=-1)  # Convert logits to probabilities\n",
    "        topk_scores, topk_indices = torch.topk(probs, k=2, dim=-1)\n",
    "\n",
    "        for token_scores, token_indices in zip(topk_scores, topk_indices):\n",
    "            for score, index in zip(token_scores, token_indices):\n",
    "                load[index] += 1\n",
    "                importance[index] += score\n",
    "\n",
    "    # Normalize importance (optional)\n",
    "    importance /= load.clamp(min=1)\n",
    "    all_loads.append(load.tolist())\n",
    "    all_importance.append(importance.tolist())\n",
    "    print(layer_name.split('.')[3])\n",
    "    \n",
    "load_matrix = np.array(all_loads)\n",
    "    # print(\"Load per expert:\", load.tolist())\n",
    "    # print(\"Importance per expert:\", importance.tolist())\n",
    "    # break\n",
    "#     # print(f\"Layer {idx} router probabilities:\")\n",
    "#     # print(f\"Shape: {probs.shape}\")\n",
    "#     # print(f\"Top-5 values per token: {torch.topk(probs, 5, dim=-1).values}\")\n",
    "#     # print(f\"Top-5 indices per token: {torch.topk(probs, 5, dim=-1).indices}\")\n",
    "#     # print(\"probs\",probs)\n",
    "#     for probs in router_probs[layer_name]:\n",
    "#     probs = F.softmax(probs, dim=-1)\n",
    "#     topk_scores, topk_indices = torch.topk(probs, 2, dim=-1)\n",
    "#     num_experts = probs.shape[-1]\n",
    "    \n",
    "#     # if idx == 1:\n",
    "#     #     break\n",
    "#     # Iterate over each token\n",
    "#     for token_topk_scores, token_topk_indices in zip(topk_scores, topk_indices):\n",
    "#         for score, index in zip(token_topk_scores, token_topk_indices):\n",
    "#             load[index] += 1\n",
    "#             importance[index] += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c91db58-3d4c-4e0a-8ec2-731be75e4d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10012882202863693,\n",
       "  0.08603515475988388,\n",
       "  0.0895182266831398,\n",
       "  0.09850383549928665,\n",
       "  0.08944424986839294,\n",
       "  0.0859375,\n",
       "  0.083251953125,\n",
       "  0.0963309183716774,\n",
       "  0.0,\n",
       "  0.0938720703125,\n",
       "  0.0888671875,\n",
       "  0.09348707646131516,\n",
       "  0.08638139069080353,\n",
       "  0.0849609375,\n",
       "  0.09521484375,\n",
       "  0.1015625],\n",
       " [0.092529296875,\n",
       "  0.0885225161910057,\n",
       "  0.0,\n",
       "  0.1258603036403656,\n",
       "  0.1151936873793602,\n",
       "  0.08349609375,\n",
       "  0.09967041015625,\n",
       "  0.14604315161705017,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.12797851860523224,\n",
       "  0.0939127579331398,\n",
       "  0.09228515625,\n",
       "  0.0,\n",
       "  0.08447265625,\n",
       "  0.03180694580078125],\n",
       " [0.1425374299287796,\n",
       "  0.14562152326107025,\n",
       "  0.19720458984375,\n",
       "  0.12371271103620529,\n",
       "  0.2115885466337204,\n",
       "  0.0,\n",
       "  0.1893310546875,\n",
       "  0.1482747346162796,\n",
       "  0.09130859375,\n",
       "  0.206787109375,\n",
       "  0.1309407502412796,\n",
       "  0.0,\n",
       "  0.154296875,\n",
       "  0.1858995258808136,\n",
       "  0.0973307266831398,\n",
       "  0.11709871888160706],\n",
       " [0.10951967537403107,\n",
       "  0.19083179533481598,\n",
       "  0.0,\n",
       "  0.10337007790803909,\n",
       "  0.340087890625,\n",
       "  0.10732422024011612,\n",
       "  0.0982530415058136,\n",
       "  0.08780517429113388,\n",
       "  0.0906948521733284,\n",
       "  0.090576171875,\n",
       "  0.1072591170668602,\n",
       "  0.0968153178691864,\n",
       "  0.0,\n",
       "  0.08349609375,\n",
       "  0.1139729842543602,\n",
       "  0.2209821492433548],\n",
       " [0.10244140774011612,\n",
       "  0.44355469942092896,\n",
       "  0.09555257111787796,\n",
       "  0.10791015625,\n",
       "  0.0,\n",
       "  0.071533203125,\n",
       "  0.07763671875,\n",
       "  0.1407877653837204,\n",
       "  0.1007661372423172,\n",
       "  0.1069878488779068,\n",
       "  0.0941162109375,\n",
       "  0.3311298191547394,\n",
       "  0.2115693986415863,\n",
       "  0.25019532442092896,\n",
       "  0.1382649689912796,\n",
       "  0.12744140625],\n",
       " [0.1080729141831398,\n",
       "  0.10484211891889572,\n",
       "  0.10120442509651184,\n",
       "  0.2859348654747009,\n",
       "  0.09619140625,\n",
       "  0.1951238512992859,\n",
       "  0.1336669921875,\n",
       "  0.06617431342601776,\n",
       "  0.121337890625,\n",
       "  0.10317623615264893,\n",
       "  0.3217494487762451,\n",
       "  0.193115234375,\n",
       "  0.0,\n",
       "  0.08935546875,\n",
       "  0.499267578125,\n",
       "  0.3261021077632904],\n",
       " [0.1008978933095932,\n",
       "  0.1905720978975296,\n",
       "  0.08554687350988388,\n",
       "  0.2321506142616272,\n",
       "  0.08203125,\n",
       "  0.0,\n",
       "  0.34930890798568726,\n",
       "  0.24600380659103394,\n",
       "  0.17177654802799225,\n",
       "  0.0968424454331398,\n",
       "  0.07177734375,\n",
       "  0.2163899689912796,\n",
       "  0.1145833358168602,\n",
       "  0.0955810546875,\n",
       "  0.12667007744312286,\n",
       "  0.09521484375],\n",
       " [0.0859375,\n",
       "  0.1411946564912796,\n",
       "  0.19045639038085938,\n",
       "  0.0,\n",
       "  0.0751953125,\n",
       "  0.09814453125,\n",
       "  0.1569010466337204,\n",
       "  0.21240234375,\n",
       "  0.1868489533662796,\n",
       "  0.1298828125,\n",
       "  0.13792318105697632,\n",
       "  0.0,\n",
       "  0.1318359375,\n",
       "  0.1474609375,\n",
       "  0.203125,\n",
       "  0.099609375],\n",
       " [0.13466796278953552,\n",
       "  0.1690630167722702,\n",
       "  0.0,\n",
       "  0.3410075008869171,\n",
       "  0.0794270858168602,\n",
       "  0.10205078125,\n",
       "  0.18853400647640228,\n",
       "  0.2207910567522049,\n",
       "  0.3126046359539032,\n",
       "  0.0830078125,\n",
       "  0.1725260466337204,\n",
       "  0.037353515625,\n",
       "  0.09207763522863388,\n",
       "  0.12248091399669647,\n",
       "  0.1046142578125,\n",
       "  0.1766357421875],\n",
       " [0.0,\n",
       "  0.09936141967773438,\n",
       "  0.12158203125,\n",
       "  0.1231485977768898,\n",
       "  0.3717595934867859,\n",
       "  0.079833984375,\n",
       "  0.103271484375,\n",
       "  0.09464111179113388,\n",
       "  0.1434493362903595,\n",
       "  0.2407938688993454,\n",
       "  0.0519866943359375,\n",
       "  0.0,\n",
       "  0.4203084409236908,\n",
       "  0.21976928412914276,\n",
       "  0.2124399095773697,\n",
       "  0.121826171875],\n",
       " [0.23294271528720856,\n",
       "  0.13087795674800873,\n",
       "  0.111328125,\n",
       "  0.5133056640625,\n",
       "  0.075439453125,\n",
       "  0.10483398288488388,\n",
       "  0.0973772332072258,\n",
       "  0.23103713989257812,\n",
       "  0.0,\n",
       "  0.18349608778953552,\n",
       "  0.09326171875,\n",
       "  0.367919921875,\n",
       "  0.2919154465198517,\n",
       "  0.1298828125,\n",
       "  0.2628417909145355,\n",
       "  0.0],\n",
       " [0.1554129421710968,\n",
       "  0.09765625,\n",
       "  0.09503173828125,\n",
       "  0.07470703125,\n",
       "  0.21181640028953552,\n",
       "  0.3482666015625,\n",
       "  0.41941922903060913,\n",
       "  0.320892333984375,\n",
       "  0.2842773497104645,\n",
       "  0.0775146484375,\n",
       "  0.0579427070915699,\n",
       "  0.1453450471162796,\n",
       "  0.1558990478515625,\n",
       "  0.082763671875,\n",
       "  0.1376953125,\n",
       "  0.3255389630794525],\n",
       " [0.1387416273355484,\n",
       "  0.1611328125,\n",
       "  0.1971435546875,\n",
       "  0.16005858778953552,\n",
       "  0.0,\n",
       "  0.1103515625,\n",
       "  0.208542600274086,\n",
       "  0.1107381209731102,\n",
       "  0.107666015625,\n",
       "  0.3508097231388092,\n",
       "  0.384521484375,\n",
       "  0.19844360649585724,\n",
       "  0.13564452528953552,\n",
       "  0.27970340847969055,\n",
       "  0.094696044921875,\n",
       "  0.1514718234539032],\n",
       " [0.21655112504959106,\n",
       "  0.2573993504047394,\n",
       "  0.121490478515625,\n",
       "  0.1123046875,\n",
       "  0.21093343198299408,\n",
       "  0.3175455629825592,\n",
       "  0.0901692733168602,\n",
       "  0.13706055283546448,\n",
       "  0.25146484375,\n",
       "  0.19827091693878174,\n",
       "  0.1013997420668602,\n",
       "  0.32951658964157104,\n",
       "  0.0,\n",
       "  0.3727678656578064,\n",
       "  0.10105590522289276,\n",
       "  0.2769368588924408],\n",
       " [0.18896484375,\n",
       "  0.1923828125,\n",
       "  0.111328125,\n",
       "  0.24265624582767487,\n",
       "  0.2061130702495575,\n",
       "  0.09592285007238388,\n",
       "  0.2308761179447174,\n",
       "  0.0771484375,\n",
       "  0.0771484375,\n",
       "  0.0,\n",
       "  0.0947265625,\n",
       "  0.054473876953125,\n",
       "  0.1464301198720932,\n",
       "  0.35881438851356506,\n",
       "  0.08642578125,\n",
       "  0.461884468793869],\n",
       " [0.100067138671875,\n",
       "  0.1832139790058136,\n",
       "  0.0978190079331398,\n",
       "  0.10369873046875,\n",
       "  0.0771484375,\n",
       "  0.12839050590991974,\n",
       "  0.30528971552848816,\n",
       "  0.08508577942848206,\n",
       "  0.1095377579331398,\n",
       "  0.358154296875,\n",
       "  0.0537109375,\n",
       "  0.09564208984375,\n",
       "  0.130859375,\n",
       "  0.4351767301559448,\n",
       "  0.112060546875,\n",
       "  0.1900634765625],\n",
       " [0.108642578125,\n",
       "  0.1768043041229248,\n",
       "  0.3042779862880707,\n",
       "  0.07989501953125,\n",
       "  0.0989990234375,\n",
       "  0.09114380180835724,\n",
       "  0.108154296875,\n",
       "  0.0830078125,\n",
       "  0.42923176288604736,\n",
       "  0.0,\n",
       "  0.1828058362007141,\n",
       "  0.2975899875164032,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08837890625,\n",
       "  0.3461216390132904],\n",
       " [0.2860351502895355,\n",
       "  0.0,\n",
       "  0.1086273193359375,\n",
       "  0.201416015625,\n",
       "  0.0938517227768898,\n",
       "  0.07080078125,\n",
       "  0.20361328125,\n",
       "  0.1183013916015625,\n",
       "  0.11865234375,\n",
       "  0.45624831318855286,\n",
       "  0.2730712890625,\n",
       "  0.0769609734416008,\n",
       "  0.0,\n",
       "  0.22357973456382751,\n",
       "  0.1352163404226303,\n",
       "  0.021617889404296875],\n",
       " [0.0,\n",
       "  0.58203125,\n",
       "  0.28416016697883606,\n",
       "  0.0,\n",
       "  0.30095213651657104,\n",
       "  0.0,\n",
       "  0.2019856721162796,\n",
       "  0.3043619692325592,\n",
       "  0.0,\n",
       "  0.2637261152267456,\n",
       "  0.038330078125,\n",
       "  0.12841796875,\n",
       "  0.2545942962169647,\n",
       "  0.21981489658355713,\n",
       "  0.2975260317325592,\n",
       "  0.2221272736787796],\n",
       " [0.029052734375,\n",
       "  0.37612104415893555,\n",
       "  0.0,\n",
       "  0.4290364682674408,\n",
       "  0.1845703125,\n",
       "  0.3600260317325592,\n",
       "  0.4386393129825592,\n",
       "  0.8359375,\n",
       "  0.27621835470199585,\n",
       "  0.414642333984375,\n",
       "  0.05712890625,\n",
       "  0.06871338188648224,\n",
       "  0.1783854216337204,\n",
       "  0.3499407172203064,\n",
       "  0.2014596164226532,\n",
       "  0.0],\n",
       " [0.1376953125,\n",
       "  0.0999348983168602,\n",
       "  0.08837890625,\n",
       "  0.038330078125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.14934997260570526,\n",
       "  0.1833120435476303,\n",
       "  0.12539061903953552,\n",
       "  0.0,\n",
       "  0.23828125,\n",
       "  0.0947062149643898,\n",
       "  0.1724853515625,\n",
       "  0.45230379700660706,\n",
       "  0.11368279904127121,\n",
       "  0.1225498765707016],\n",
       " [0.0,\n",
       "  0.1881103515625,\n",
       "  0.0,\n",
       "  0.1729181408882141,\n",
       "  0.09130859375,\n",
       "  0.15894775092601776,\n",
       "  0.0634969100356102,\n",
       "  0.3666827976703644,\n",
       "  0.0,\n",
       "  0.1109619140625,\n",
       "  0.3856835961341858,\n",
       "  0.5944010615348816,\n",
       "  0.0,\n",
       "  0.7261718511581421,\n",
       "  0.1001993790268898,\n",
       "  0.3008858859539032],\n",
       " [0.120941162109375,\n",
       "  0.16415128111839294,\n",
       "  0.2323947548866272,\n",
       "  0.11279296875,\n",
       "  0.13893482089042664,\n",
       "  0.093994140625,\n",
       "  0.507617175579071,\n",
       "  0.3353707492351532,\n",
       "  0.08447265625,\n",
       "  0.24903421103954315,\n",
       "  0.3808651864528656,\n",
       "  0.3440755307674408,\n",
       "  0.123291015625,\n",
       "  0.2366769015789032,\n",
       "  0.11526361852884293,\n",
       "  0.0],\n",
       " [0.3356730043888092,\n",
       "  0.2177530974149704,\n",
       "  0.138916015625,\n",
       "  0.1298828125,\n",
       "  0.2002737820148468,\n",
       "  0.1795654296875,\n",
       "  0.049560546875,\n",
       "  0.3291148245334625,\n",
       "  0.240966796875,\n",
       "  0.0869140625,\n",
       "  0.0973307266831398,\n",
       "  0.20048384368419647,\n",
       "  0.26599884033203125,\n",
       "  0.0,\n",
       "  0.5425781011581421,\n",
       "  0.0],\n",
       " [0.43505859375,\n",
       "  0.05126953125,\n",
       "  0.0,\n",
       "  0.27392578125,\n",
       "  0.0,\n",
       "  0.27010831236839294,\n",
       "  0.294921875,\n",
       "  0.29314056038856506,\n",
       "  0.1901598423719406,\n",
       "  0.3694254457950592,\n",
       "  0.13259276747703552,\n",
       "  0.3025645315647125,\n",
       "  0.238739013671875,\n",
       "  0.10650634765625,\n",
       "  0.2403913289308548,\n",
       "  0.0],\n",
       " [0.324951171875,\n",
       "  0.08251953125,\n",
       "  0.23626913130283356,\n",
       "  0.09459228813648224,\n",
       "  0.3670285642147064,\n",
       "  0.501708984375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.345977783203125,\n",
       "  0.09814453125,\n",
       "  0.1868218332529068,\n",
       "  0.0979817733168602,\n",
       "  0.0953369140625,\n",
       "  0.308929443359375,\n",
       "  0.19473877549171448,\n",
       "  0.3277587890625],\n",
       " [0.1483154296875,\n",
       "  0.0233154296875,\n",
       "  0.4599609375,\n",
       "  0.0,\n",
       "  0.654101550579071,\n",
       "  0.4615693986415863,\n",
       "  0.0,\n",
       "  0.36856192350387573,\n",
       "  0.1484375,\n",
       "  0.19316406548023224,\n",
       "  0.2897662818431854,\n",
       "  0.093505859375,\n",
       "  0.0,\n",
       "  0.2259521484375,\n",
       "  0.044677734375,\n",
       "  0.2400430142879486],\n",
       " [0.19140625,\n",
       "  0.3140502870082855,\n",
       "  0.8373326063156128,\n",
       "  0.30365410447120667,\n",
       "  0.0,\n",
       "  0.146392822265625,\n",
       "  0.2549383044242859,\n",
       "  0.16447754204273224,\n",
       "  0.2601725161075592,\n",
       "  0.084228515625,\n",
       "  0.1026204451918602,\n",
       "  0.12131500244140625,\n",
       "  0.0525716133415699,\n",
       "  0.4254557192325592,\n",
       "  0.0,\n",
       "  0.4775448739528656],\n",
       " [0.35986328125,\n",
       "  0.095703125,\n",
       "  0.10014648735523224,\n",
       "  0.3716905415058136,\n",
       "  0.128173828125,\n",
       "  0.2439236044883728,\n",
       "  0.199951171875,\n",
       "  0.0,\n",
       "  0.40818360447883606,\n",
       "  0.14931945502758026,\n",
       "  0.3843750059604645,\n",
       "  0.1302083283662796,\n",
       "  0.2902560830116272,\n",
       "  0.29013460874557495,\n",
       "  0.109375,\n",
       "  0.1815863698720932],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.2588984966278076,\n",
       "  0.3082682192325592,\n",
       "  0.26661840081214905,\n",
       "  0.4651855528354645,\n",
       "  0.52734375,\n",
       "  0.0,\n",
       "  0.21274414658546448,\n",
       "  0.205078125,\n",
       "  0.3461339473724365,\n",
       "  0.0,\n",
       "  0.23828125,\n",
       "  0.34561631083488464,\n",
       "  0.3587890565395355,\n",
       "  0.1982964426279068],\n",
       " [0.279876708984375,\n",
       "  0.0,\n",
       "  0.090576171875,\n",
       "  0.3349609375,\n",
       "  0.0802408829331398,\n",
       "  0.3360005021095276,\n",
       "  0.10302734375,\n",
       "  0.1751360148191452,\n",
       "  0.1748046875,\n",
       "  0.0,\n",
       "  0.697460949420929,\n",
       "  0.0,\n",
       "  0.1993963122367859,\n",
       "  0.4291829466819763,\n",
       "  0.095703125,\n",
       "  0.11669921875],\n",
       " [0.12939453125,\n",
       "  0.0,\n",
       "  0.17827148735523224,\n",
       "  0.196044921875,\n",
       "  0.2229817658662796,\n",
       "  0.931640625,\n",
       "  0.32888031005859375,\n",
       "  0.4446115791797638,\n",
       "  0.0,\n",
       "  0.1667829304933548,\n",
       "  0.1328125,\n",
       "  0.1416792869567871,\n",
       "  0.3655894994735718,\n",
       "  0.07028961181640625,\n",
       "  0.2425181120634079,\n",
       "  0.3135811984539032],\n",
       " [0.0,\n",
       "  0.3763020932674408,\n",
       "  0.0,\n",
       "  0.12451171875,\n",
       "  0.4921061098575592,\n",
       "  0.28972604870796204,\n",
       "  0.5759024620056152,\n",
       "  0.0,\n",
       "  0.1753607839345932,\n",
       "  0.17822265625,\n",
       "  0.0,\n",
       "  0.0762125626206398,\n",
       "  0.12060546875,\n",
       "  0.4068501889705658,\n",
       "  0.2288365513086319,\n",
       "  0.0],\n",
       " [0.1354166716337204,\n",
       "  0.3149834871292114,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3594447672367096,\n",
       "  0.14453125,\n",
       "  0.1990559846162796,\n",
       "  0.07373046875,\n",
       "  0.2740478515625,\n",
       "  0.3824637234210968,\n",
       "  0.45905762910842896,\n",
       "  0.2463550567626953,\n",
       "  0.332483172416687,\n",
       "  0.2803955078125,\n",
       "  0.1724446564912796],\n",
       " [0.3142143189907074,\n",
       "  0.3040945827960968,\n",
       "  0.3174682557582855,\n",
       "  0.0,\n",
       "  0.1569010466337204,\n",
       "  0.3000549376010895,\n",
       "  0.1551920622587204,\n",
       "  0.4399445354938507,\n",
       "  0.243682861328125,\n",
       "  0.3309529721736908,\n",
       "  0.680908203125,\n",
       "  0.17252223193645477,\n",
       "  0.09462391585111618,\n",
       "  0.2446831613779068,\n",
       "  0.3008626401424408,\n",
       "  0.00154876708984375],\n",
       " [0.076904296875,\n",
       "  0.35612329840660095,\n",
       "  0.11284179985523224,\n",
       "  0.1712646484375,\n",
       "  0.4148571491241455,\n",
       "  0.22265625,\n",
       "  0.0,\n",
       "  0.3717840909957886,\n",
       "  0.077880859375,\n",
       "  0.052490234375,\n",
       "  0.4068603515625,\n",
       "  0.1009114608168602,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.410757452249527,\n",
       "  0.0],\n",
       " [0.1765460968017578,\n",
       "  0.08837890625,\n",
       "  0.047431182116270065,\n",
       "  0.6565136909484863,\n",
       "  0.36708012223243713,\n",
       "  0.2142995148897171,\n",
       "  0.3308563232421875,\n",
       "  0.0745697021484375,\n",
       "  0.14529570937156677,\n",
       "  0.30827054381370544,\n",
       "  0.0,\n",
       "  0.00927734375,\n",
       "  0.237579345703125,\n",
       "  0.07763671875,\n",
       "  0.2679036557674408,\n",
       "  0.08178671449422836],\n",
       " [0.31777581572532654,\n",
       "  0.3459123969078064,\n",
       "  0.13853870332241058,\n",
       "  0.12173227220773697,\n",
       "  0.0203857421875,\n",
       "  0.1748046875,\n",
       "  0.1455426961183548,\n",
       "  0.1284993439912796,\n",
       "  0.0,\n",
       "  0.1575520783662796,\n",
       "  0.298828125,\n",
       "  0.17256887257099152,\n",
       "  0.2785069942474365,\n",
       "  0.0,\n",
       "  0.1090291365981102,\n",
       "  0.29207152128219604],\n",
       " [0.0135955810546875,\n",
       "  0.0,\n",
       "  0.0484619140625,\n",
       "  0.1825212687253952,\n",
       "  0.0,\n",
       "  0.0054168701171875,\n",
       "  0.1943359375,\n",
       "  0.0893402099609375,\n",
       "  0.5289039611816406,\n",
       "  0.042157236486673355,\n",
       "  0.0,\n",
       "  0.1369086354970932,\n",
       "  0.06984095275402069,\n",
       "  0.3102050721645355,\n",
       "  0.15336914360523224,\n",
       "  0.821179211139679],\n",
       " [0.13017578423023224,\n",
       "  0.26629638671875,\n",
       "  0.1145172119140625,\n",
       "  0.0771484375,\n",
       "  0.24279391765594482,\n",
       "  0.1270926296710968,\n",
       "  0.1595865935087204,\n",
       "  0.15312500298023224,\n",
       "  0.33263441920280457,\n",
       "  0.133544921875,\n",
       "  0.2890978455543518,\n",
       "  0.287567138671875,\n",
       "  0.32177734375,\n",
       "  0.1946818083524704,\n",
       "  0.105712890625,\n",
       "  0.22995606064796448],\n",
       " [0.01141357421875,\n",
       "  0.0921223983168602,\n",
       "  0.38623046875,\n",
       "  0.7663474082946777,\n",
       "  0.2202099859714508,\n",
       "  0.1382228285074234,\n",
       "  0.010044097900390625,\n",
       "  0.0,\n",
       "  0.3165447413921356,\n",
       "  0.0025787353515625,\n",
       "  0.04010009765625,\n",
       "  0.2154541015625,\n",
       "  0.1287740021944046,\n",
       "  0.041914720088243484,\n",
       "  0.2696777284145355,\n",
       "  0.059741973876953125],\n",
       " [0.15171051025390625,\n",
       "  0.3667491674423218,\n",
       "  0.0582682304084301,\n",
       "  0.1331787109375,\n",
       "  0.2098032683134079,\n",
       "  0.19595101475715637,\n",
       "  0.1859283447265625,\n",
       "  0.4204021990299225,\n",
       "  0.1449381560087204,\n",
       "  0.217041015625,\n",
       "  0.4104817807674408,\n",
       "  0.5889369249343872,\n",
       "  0.1602838635444641,\n",
       "  0.17304687201976776,\n",
       "  0.046661376953125,\n",
       "  0.35186994075775146],\n",
       " [0.0,\n",
       "  0.3820106089115143,\n",
       "  0.0218505859375,\n",
       "  0.1982421875,\n",
       "  0.08835338056087494,\n",
       "  0.0,\n",
       "  0.109130859375,\n",
       "  0.0,\n",
       "  0.0924479141831398,\n",
       "  0.2099507600069046,\n",
       "  0.0,\n",
       "  0.3277702331542969,\n",
       "  0.2756767272949219,\n",
       "  0.0013529459247365594,\n",
       "  0.0474853515625,\n",
       "  0.6139810085296631],\n",
       " [0.26416015625,\n",
       "  0.28125,\n",
       "  0.1923828125,\n",
       "  0.1360386461019516,\n",
       "  0.1021728515625,\n",
       "  0.18267822265625,\n",
       "  0.3506208062171936,\n",
       "  0.20976562798023224,\n",
       "  0.14786304533481598,\n",
       "  0.09462890774011612,\n",
       "  0.4013509154319763,\n",
       "  0.14111328125,\n",
       "  0.1708984375,\n",
       "  0.23405317962169647,\n",
       "  0.24405057728290558,\n",
       "  0.419921875],\n",
       " [0.1636962890625,\n",
       "  0.2609093189239502,\n",
       "  0.1736886203289032,\n",
       "  0.15964919328689575,\n",
       "  0.1055908203125,\n",
       "  0.1171875,\n",
       "  0.1539306640625,\n",
       "  0.1536458283662796,\n",
       "  0.1119559183716774,\n",
       "  0.20253905653953552,\n",
       "  0.25242069363594055,\n",
       "  0.2253766804933548,\n",
       "  0.2214626669883728,\n",
       "  0.171142578125,\n",
       "  0.3141683042049408,\n",
       "  0.236419677734375],\n",
       " [0.18088379502296448,\n",
       "  0.0848846435546875,\n",
       "  0.0752766951918602,\n",
       "  0.16650390625,\n",
       "  0.49856388568878174,\n",
       "  0.0944010391831398,\n",
       "  0.130859375,\n",
       "  0.13596192002296448,\n",
       "  0.2720947265625,\n",
       "  0.2327357679605484,\n",
       "  0.2764214277267456,\n",
       "  0.16785778105258942,\n",
       "  0.1229248046875,\n",
       "  0.1839192658662796,\n",
       "  0.11376953125,\n",
       "  0.1281467080116272],\n",
       " [0.09130859375,\n",
       "  0.0,\n",
       "  0.1772562712430954,\n",
       "  0.0,\n",
       "  0.7735644578933716,\n",
       "  0.0,\n",
       "  0.03436279296875,\n",
       "  0.49189454317092896,\n",
       "  0.1171875,\n",
       "  0.263671875,\n",
       "  0.35833740234375,\n",
       "  0.16017228364944458,\n",
       "  0.439453125,\n",
       "  0.5111491084098816,\n",
       "  0.002655029296875,\n",
       "  0.0],\n",
       " [0.16316303610801697,\n",
       "  0.1630859375,\n",
       "  0.14888139069080353,\n",
       "  0.0,\n",
       "  0.31891000270843506,\n",
       "  0.0997721329331398,\n",
       "  0.0,\n",
       "  0.33935546875,\n",
       "  0.15059299767017365,\n",
       "  0.0,\n",
       "  0.12530158460140228,\n",
       "  0.1400824636220932,\n",
       "  0.1504313200712204,\n",
       "  0.19618576765060425,\n",
       "  0.2107747346162796,\n",
       "  0.20138970017433167]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27779f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Convert to NumPy array for plotting\n",
    "load_matrix = all_loads\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(load_matrix, cmap=\"YlGnBu\", annot=False, cbar=True, xticklabels=[f\"E{i}\" for i in range(num_experts)], yticklabels=[f\"L{i}\" for i in range(num_layers)])\n",
    "\n",
    "plt.title(\"Expert Token Load Heatmap Across MoE Layers\", fontsize=16)\n",
    "plt.xlabel(\"Expert Index\", fontsize=12)\n",
    "plt.ylabel(\"Layer Index\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a7011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 :\n",
      "Kept experts: [6, 5, 2, 1, 10, 14, 9, 15, 12, 4, 7, 11, 0, 3]\n",
      "Prune experts: [8, 13]\n",
      "Layer 1 :\n",
      "Kept experts: [9, 13, 15, 5, 14, 0, 11, 12, 6, 1, 10, 4, 3, 7]\n",
      "Prune experts: [2, 8]\n",
      "Layer 2 :\n",
      "Kept experts: [8, 14, 10, 3, 7, 12, 0, 15, 6, 9, 4, 13, 2, 1]\n",
      "Prune experts: [5, 11]\n",
      "Layer 3 :\n",
      "Kept experts: [9, 13, 5, 6, 7, 10, 8, 11, 4, 15, 1, 14, 3, 0]\n",
      "Prune experts: [2, 12]\n",
      "Layer 4 :\n",
      "Kept experts: [5, 10, 0, 3, 15, 7, 2, 14, 8, 13, 9, 11, 1, 12]\n",
      "Prune experts: [4, 6]\n",
      "Layer 5 :\n",
      "Kept experts: [7, 13, 0, 8, 6, 11, 2, 1, 5, 15, 9, 14, 3, 10]\n",
      "Prune experts: [4, 12]\n",
      "Layer 6 :\n",
      "Kept experts: [10, 2, 15, 12, 9, 0, 14, 1, 11, 13, 8, 3, 6, 7]\n",
      "Prune experts: [4, 5]\n",
      "Layer 7 :\n",
      "Kept experts: [4, 0, 5, 15, 9, 13, 1, 6, 10, 8, 12, 14, 7, 2]\n",
      "Prune experts: [3, 11]\n",
      "Layer 8 :\n",
      "Kept experts: [9, 4, 0, 12, 5, 10, 13, 14, 15, 6, 1, 8, 7, 3]\n",
      "Prune experts: [2, 11]\n",
      "Layer 9 :\n",
      "Kept experts: [10, 5, 15, 6, 2, 7, 1, 9, 13, 3, 14, 12, 8, 4]\n",
      "Prune experts: [0, 11]\n",
      "Layer 10 :\n",
      "Kept experts: [10, 2, 13, 4, 5, 6, 0, 11, 1, 14, 9, 3, 7, 12]\n",
      "Prune experts: [8, 15]\n",
      "Layer 11 :\n",
      "Kept experts: [9, 13, 1, 2, 14, 11, 0, 12, 4, 8, 5, 7, 6, 15]\n",
      "Prune experts: [3, 10]\n",
      "Layer 12 :\n",
      "Kept experts: [14, 7, 8, 0, 3, 1, 15, 12, 2, 11, 6, 10, 9, 13]\n",
      "Prune experts: [4, 5]\n",
      "Layer 13 :\n",
      "Kept experts: [3, 6, 7, 2, 8, 14, 5, 9, 1, 0, 15, 13, 11, 4]\n",
      "Prune experts: [10, 12]\n",
      "Layer 14 :\n",
      "Kept experts: [11, 7, 8, 10, 2, 1, 5, 0, 12, 4, 3, 13, 6, 15]\n",
      "Prune experts: [9, 14]\n",
      "Layer 15 :\n",
      "Kept experts: [14, 8, 0, 3, 4, 11, 12, 5, 7, 1, 15, 6, 9, 13]\n",
      "Prune experts: [2, 10]\n",
      "Layer 16 :\n",
      "Kept experts: [13, 3, 7, 14, 6, 4, 0, 5, 10, 15, 1, 11, 2, 8]\n",
      "Prune experts: [9, 12]\n",
      "Layer 17 :\n",
      "Kept experts: [15, 5, 8, 2, 7, 11, 6, 14, 3, 4, 0, 13, 10, 9]\n",
      "Prune experts: [1, 12]\n",
      "Layer 18 :\n",
      "Kept experts: [5, 8, 10, 11, 6, 14, 15, 7, 9, 4, 1, 2, 13, 12]\n",
      "Prune experts: [0, 3]\n",
      "Layer 19 :\n",
      "Kept experts: [0, 10, 11, 4, 12, 5, 14, 3, 13, 6, 9, 7, 1, 8]\n",
      "Prune experts: [2, 15]\n",
      "Layer 20 :\n",
      "Kept experts: [9, 3, 2, 11, 1, 0, 8, 15, 12, 14, 10, 7, 6, 13]\n",
      "Prune experts: [4, 5]\n",
      "Layer 21 :\n",
      "Kept experts: [8, 12, 4, 6, 9, 14, 5, 1, 3, 11, 15, 13, 10, 7]\n",
      "Prune experts: [0, 2]\n",
      "Layer 22 :\n",
      "Kept experts: [3, 8, 12, 0, 14, 1, 2, 13, 11, 9, 4, 10, 7, 6]\n",
      "Prune experts: [5, 15]\n",
      "Layer 23 :\n",
      "Kept experts: [6, 9, 10, 3, 2, 5, 11, 1, 4, 8, 14, 0, 12, 7]\n",
      "Prune experts: [13, 15]\n",
      "Layer 24 :\n",
      "Kept experts: [15, 1, 13, 10, 3, 6, 8, 14, 12, 5, 9, 0, 11, 7]\n",
      "Prune experts: [2, 4]\n",
      "Layer 25 :\n",
      "Kept experts: [1, 12, 9, 11, 3, 10, 14, 15, 13, 8, 0, 2, 5, 4]\n",
      "Prune experts: [6, 7]\n",
      "Layer 26 :\n",
      "Kept experts: [12, 1, 14, 11, 8, 0, 9, 2, 13, 5, 4, 7, 15, 10]\n",
      "Prune experts: [3, 6]\n",
      "Layer 27 :\n",
      "Kept experts: [12, 9, 10, 0, 11, 5, 7, 6, 1, 13, 8, 2, 15, 3]\n",
      "Prune experts: [4, 14]\n",
      "Layer 28 :\n",
      "Kept experts: [14, 11, 2, 4, 6, 15, 9, 5, 12, 0, 10, 3, 8, 13]\n",
      "Prune experts: [1, 7]\n",
      "Layer 29 :\n",
      "Kept experts: [7, 11, 9, 12, 15, 8, 3, 14, 10, 6, 2, 4, 5, 13]\n",
      "Prune experts: [0, 1]\n",
      "Layer 30 :\n",
      "Kept experts: [11, 2, 14, 15, 6, 8, 4, 7, 0, 3, 10, 5, 12, 13]\n",
      "Prune experts: [1, 9]\n",
      "Layer 31 :\n",
      "Kept experts: [10, 9, 0, 2, 15, 13, 4, 3, 11, 6, 14, 12, 5, 7]\n",
      "Prune experts: [1, 8]\n",
      "Layer 32 :\n",
      "Kept experts: [7, 10, 15, 11, 12, 3, 9, 8, 1, 14, 4, 5, 6, 13]\n",
      "Prune experts: [0, 2]\n",
      "Layer 33 :\n",
      "Kept experts: [4, 8, 6, 0, 7, 15, 12, 14, 5, 9, 10, 1, 11, 13]\n",
      "Prune experts: [2, 3]\n",
      "Layer 34 :\n",
      "Kept experts: [6, 4, 12, 11, 13, 5, 1, 9, 8, 2, 14, 0, 10, 7]\n",
      "Prune experts: [3, 15]\n",
      "Layer 35 :\n",
      "Kept experts: [13, 15, 9, 0, 8, 11, 2, 3, 5, 10, 1, 7, 14, 4]\n",
      "Prune experts: [6, 12]\n",
      "Layer 36 :\n",
      "Kept experts: [13, 2, 7, 1, 15, 8, 0, 14, 12, 5, 6, 9, 4, 3]\n",
      "Prune experts: [10, 11]\n",
      "Layer 37 :\n",
      "Kept experts: [4, 14, 7, 9, 5, 2, 3, 6, 11, 15, 12, 1, 10, 0]\n",
      "Prune experts: [8, 13]\n",
      "Layer 38 :\n",
      "Kept experts: [10, 5, 0, 2, 7, 6, 14, 11, 3, 9, 13, 12, 8, 15]\n",
      "Prune experts: [1, 4]\n",
      "Layer 39 :\n",
      "Kept experts: [9, 0, 2, 5, 7, 6, 13, 15, 1, 12, 8, 11, 4, 10]\n",
      "Prune experts: [3, 14]\n",
      "Layer 40 :\n",
      "Kept experts: [0, 6, 10, 15, 1, 13, 12, 5, 11, 14, 2, 8, 4, 3]\n",
      "Prune experts: [7, 9]\n",
      "Layer 41 :\n",
      "Kept experts: [3, 8, 13, 4, 6, 12, 9, 5, 0, 10, 1, 11, 15, 7]\n",
      "Prune experts: [2, 14]\n",
      "Layer 42 :\n",
      "Kept experts: [7, 10, 13, 2, 14, 8, 6, 4, 3, 9, 12, 11, 1, 15]\n",
      "Prune experts: [0, 5]\n",
      "Layer 43 :\n",
      "Kept experts: [3, 11, 12, 2, 5, 7, 8, 0, 1, 13, 15, 6, 10, 14]\n",
      "Prune experts: [4, 9]\n",
      "Layer 44 :\n",
      "Kept experts: [8, 13, 0, 7, 6, 2, 9, 12, 3, 15, 10, 11, 14, 1]\n",
      "Prune experts: [4, 5]\n",
      "Layer 45 :\n",
      "Kept experts: [6, 14, 12, 1, 15, 13, 7, 8, 3, 0, 11, 10, 9, 4]\n",
      "Prune experts: [2, 5]\n",
      "Layer 46 :\n",
      "Kept experts: [5, 15, 14, 6, 0, 8, 2, 9, 10, 12, 13, 7, 11, 4]\n",
      "Prune experts: [1, 3]\n",
      "Layer 47 :\n",
      "Kept experts: [9, 5, 1, 12, 11, 2, 10, 14, 8, 13, 0, 7, 15, 4]\n",
      "Prune experts: [3, 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "kept_experts = []\n",
    "pruned_experts = []\n",
    "def rank_and_select_experts(load, importance, keep_ratio=0.9, alpha=0.5):\n",
    "    load = np.array(load)\n",
    "    importance = np.array(importance)\n",
    "\n",
    "    # Normalize\n",
    "    norm_load = (load - load.min()) / (load.max() - load.min() + 1e-6)\n",
    "    norm_importance = (importance - importance.min()) / (importance.max() - importance.min() + 1e-6)\n",
    "\n",
    "    # Weighted score\n",
    "    scores = alpha * norm_load + (1 - alpha) * norm_importance\n",
    "    num_keep = int(len(scores) * keep_ratio)\n",
    "    keep_indices = np.argsort(scores)[-num_keep:]\n",
    "    \n",
    "    prune_indices = np.setdiff1d(np.arange(len(scores)), keep_indices)\n",
    "    \n",
    "    return keep_indices.tolist(), prune_indices.tolist()\n",
    "\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    keep_indices, prune_indices = rank_and_select_experts(all_loads[layer], all_importance[layer])\n",
    "    print(f\"Layer {layer} :\")\n",
    "    print(f\"Kept experts: {keep_indices}\")\n",
    "    print(f\"Prune experts: {prune_indices}\")\n",
    "    kept_experts.append(keep_indices)\n",
    "    pruned_experts.append(prune_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb5538d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama4TextDecoderLayer(\n",
      "  (self_attn): Llama4TextAttention(\n",
      "    (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "    (k_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=5120, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "    (qk_norm): Llama4TextL2Norm(eps=1e-05)\n",
      "  )\n",
      "  (feed_forward): Llama4TextMoe(\n",
      "    (experts): Llama4TextExperts(\n",
      "      (act_fn): SiLU()\n",
      "    )\n",
      "    (router): Linear(in_features=5120, out_features=16, bias=False)\n",
      "    (shared_expert): Llama4TextMLP(\n",
      "      (gate_proj): Linear(in_features=5120, out_features=8192, bias=False)\n",
      "      (up_proj): Linear(in_features=5120, out_features=8192, bias=False)\n",
      "      (down_proj): Linear(in_features=8192, out_features=5120, bias=False)\n",
      "      (activation_fn): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (input_layernorm): Llama4TextRMSNorm((5120,), eps=1e-05)\n",
      "  (post_attention_layernorm): Llama4TextRMSNorm((5120,), eps=1e-05)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.language_model.model.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d2b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752317a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94d859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###OLD VERSION\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class PrunedLlama4TextMoe(nn.Module):\n",
    "#     def __init__(self, original_moe_layer, kept_indices):\n",
    "#         super().__init__()\n",
    "#         shared = original_moe_layer.shared_expert\n",
    "#         self.hidden_size = shared.down_proj.out_features\n",
    "#         self.intermediate_size = shared.up_proj.out_features\n",
    "#         self.num_experts = len(kept_indices)\n",
    "#         self.kept_indices = kept_indices\n",
    "\n",
    "#         # Router is still linear, but we slice output to only kept experts\n",
    "#         self.router = original_moe_layer.router\n",
    "\n",
    "#         # Reference the shared expert module (assumes shared across experts)\n",
    "#         self.shared_expert = original_moe_layer.shared_expert\n",
    "\n",
    "#         # Store act_fn used inside Llama4TextExperts\n",
    "#         self.act_fn = original_moe_layer.experts.act_fn\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [batch, seq_len, hidden_size]\n",
    "#         B, S, H = x.shape\n",
    "#         x_flat = x.view(-1, H)  # [B*S, H]\n",
    "\n",
    "#         # Compute router logits and select only kept experts\n",
    "#         logits = self.router(x_flat)  # [B*S, original_num_experts]\n",
    "#         logits_subset = logits[:, self.kept_indices]  # [B*S, num_kept_experts]\n",
    "\n",
    "#         # Softmax over selected experts\n",
    "#         dispatch_probs = F.softmax(logits_subset, dim=-1)  # [B*S, num_kept_experts]\n",
    "\n",
    "#         # Dispatch inputs to experts using weighted sum of shared expert output\n",
    "#         expert_outputs = []\n",
    "#         for i, expert_idx in enumerate(self.kept_indices):\n",
    "#             expert_output = self.shared_expert(x_flat)  # [B*S, H]\n",
    "#             expert_outputs.append(expert_output.unsqueeze(1))\n",
    "\n",
    "#         stacked_outputs = torch.cat(expert_outputs, dim=1)  # [B*S, num_kept_experts, H]\n",
    "#         out = torch.sum(stacked_outputs * dispatch_probs.unsqueeze(-1), dim=1)  # [B*S, H]\n",
    "\n",
    "#         return out.view(B, S, H), logits_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bf781-d66a-4c6f-9ddc-12bf408adada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class PrunedLlama4TextMoe(nn.Module):\n",
    "#     def __init__(self, original_moe_layer, kept_indices):\n",
    "#         super().__init__()\n",
    "#         shared = original_moe_layer.shared_expert\n",
    "#         self.hidden_size = shared.down_proj.out_features\n",
    "#         self.intermediate_size = shared.up_proj.out_features\n",
    "#         self.num_experts = len(kept_indices)\n",
    "#         self.kept_indices = kept_indices\n",
    "\n",
    "#         # Construct a new router to only output logits for kept experts\n",
    "#         self.device = original_moe_layer.router.weight.device\n",
    "#         self.dtype = original_moe_layer.router.weight.dtype\n",
    "#         in_dim = original_moe_layer.router.in_features\n",
    "\n",
    "#         self.router = nn.Linear(in_dim, len(kept_indices), bias=False).to(device=self.device, dtype=self.dtype)\n",
    "#         with torch.no_grad():\n",
    "#             self.router.weight.copy_(original_moe_layer.router.weight[kept_indices].to(device=self.device, dtype=self.dtype))\n",
    "\n",
    "#         self.shared_expert = original_moe_layer.shared_expert.to(device=self.device, dtype=self.dtype)\n",
    "#         self.act_fn = original_moe_layer.experts.act_fn.to(device=self.device)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [batch, seq_len, hidden_size]\n",
    "#         x = x.to(device=self.device, dtype=self.dtype)\n",
    "#         B, S, H = x.shape\n",
    "#         x_flat = x.view(-1, H)  # [B*S, H]\n",
    "\n",
    "#         # Compute router logits (only for kept experts)\n",
    "#         logits = self.router(x_flat).to(device=self.device)  # [B*S, num_kept_experts]\n",
    "#         logits_subset = logits[:, self.kept_indices]  # [B*S, num_kept_experts]\n",
    "#         dispatch_probs = F.softmax(logits_subset, dim=-1)  # [B*S, num_kept_experts]\n",
    "\n",
    "#         # Call the shared expert once\n",
    "#         expert_output = self.shared_expert(x_flat)  # [B*S, H]\n",
    "\n",
    "#         # Broadcast and weight expert output across kept expert dimension\n",
    "#         expert_output = expert_output.unsqueeze(1).expand(-1, self.num_experts, -1)\n",
    "#         out = torch.sum(dispatch_probs.unsqueeze(-1) * expert_output, dim=1)  # [B*S, H]\n",
    "\n",
    "#         return out.view(B, S, H), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ac2f7f-0a1b-4b6e-bd42-cb4a6ad5bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORNING CODE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PrunedLlama4TextMoe(nn.Module):\n",
    "    def __init__(self, original_moe_layer, kept_indices):\n",
    "        super().__init__()\n",
    "        self.shared_expert = original_moe_layer.shared_expert\n",
    "        self.act_fn       = original_moe_layer.experts.act_fn\n",
    "\n",
    "        # Keep the full router, but remember which experts to mute\n",
    "        self.router       = original_moe_layer.router\n",
    "        self.num_experts  = self.router.out_features\n",
    "\n",
    "        # Build a boolean mask: True for kept, False for pruned\n",
    "        mask = torch.ones(self.num_experts, dtype=torch.bool, \n",
    "                           device=self.router.weight.device)\n",
    "        mask[kept_indices] = False\n",
    "        self.register_buffer('kept_mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, S, H]\n",
    "        B, S, H = x.shape\n",
    "        x_flat = x.view(-1, H)                 # [B*S, H]\n",
    "\n",
    "        # 1) compute full logits: [B*S, E]\n",
    "        logits_full = self.router(x_flat)\n",
    "\n",
    "        # 2) mask out the pruned experts by setting their logits to -inf\n",
    "        #    so their softmax probability becomes zero:\n",
    "        masked_logits = logits_full.masked_fill(~self.kept_mask, float('-inf'))\n",
    "\n",
    "        # 3) softmax over all E experts (pruned ones get zero prob)\n",
    "        dispatch_probs = F.softmax(masked_logits, dim=-1)  # [B*S, E]\n",
    "\n",
    "        # 4) run the shared expert once\n",
    "        expert_out = self.shared_expert(x_flat)            # [B*S, H]\n",
    "        expanded   = expert_out.unsqueeze(1)               # [B*S, 1, H]\n",
    "        expanded   = expanded.expand(-1, self.num_experts, -1)  # [B*S, E, H]\n",
    "\n",
    "        # 5) weight & sum across the expert dimension\n",
    "        out_flat = (dispatch_probs.unsqueeze(-1) * expanded).sum(dim=1)  # [B*S, H]\n",
    "        out      = out_flat.view(B, S, H)\n",
    "\n",
    "        # return the final MoE output plus the original-shaped logits\n",
    "        return out, logits_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33d261ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [8, 13, 16]\n",
      "1 [2, 8, 16]\n",
      "2 [5, 11, 16]\n",
      "3 [2, 12, 16]\n",
      "4 [4, 6, 16]\n",
      "5 [4, 12, 16]\n",
      "6 [4, 5, 16]\n",
      "7 [3, 11, 16]\n",
      "8 [2, 11, 16]\n",
      "9 [0, 11, 16]\n",
      "10 [8, 15, 16]\n",
      "11 [3, 10, 16]\n",
      "12 [4, 5, 16]\n",
      "13 [10, 12, 16]\n",
      "14 [9, 14, 16]\n",
      "15 [2, 10, 16]\n",
      "16 [9, 12, 16]\n",
      "17 [1, 12, 16]\n",
      "18 [0, 3, 16]\n",
      "19 [2, 15, 16]\n",
      "20 [4, 5, 16]\n",
      "21 [0, 2, 16]\n",
      "22 [5, 15, 16]\n",
      "23 [13, 15, 16]\n",
      "24 [2, 4, 16]\n",
      "25 [6, 7, 16]\n",
      "26 [3, 6, 16]\n",
      "27 [4, 14, 16]\n",
      "28 [1, 7, 16]\n",
      "29 [0, 1, 16]\n",
      "30 [1, 9, 16]\n",
      "31 [1, 8, 16]\n",
      "32 [0, 2, 16]\n",
      "33 [2, 3, 16]\n",
      "34 [3, 15, 16]\n",
      "35 [6, 12, 16]\n",
      "36 [10, 11, 16]\n",
      "37 [8, 13, 16]\n",
      "38 [1, 4, 16]\n",
      "39 [3, 14, 16]\n",
      "40 [7, 9, 16]\n",
      "41 [2, 14, 16]\n",
      "42 [0, 5, 16]\n",
      "43 [4, 9, 16]\n",
      "44 [4, 5, 16]\n",
      "45 [2, 5, 16]\n",
      "46 [1, 3, 16]\n",
      "47 [3, 6, 16]\n"
     ]
    }
   ],
   "source": [
    "# import copy\n",
    "# pruned_model = copy.deepcopy(model)\n",
    "for i, layer in enumerate(model.language_model.model.layers):\n",
    "    kept = kept_experts[i]  # From your pruning strategy\n",
    "    num = [i for i in range(0, 17) if i not in kept]\n",
    "    print(i,num)\n",
    "    # orig_moe = layer.feed_forward\n",
    "    # layer.feed_forward = PrunedLlama4TextMoe(orig_moe, kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dad90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer.feed_forward.experts._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d160f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0.0018 seconds\n",
      "Generation time: 5.0216 seconds\n",
      "Decoding time: 0.0004 seconds\n",
      "Total time: 5.0238 seconds\n",
      "\n",
      "Generated text:\n",
      "hello \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "assistant \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"hello \" },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Start timing\n",
    "start_total = time.time()\n",
    "\n",
    "# Time the processing part\n",
    "start_process = time.time()\n",
    "tokenized = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    ")\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "process_time = time.time() - start_process\n",
    "\n",
    "# Time the generation part\n",
    "start_generate = time.time()\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    return_dict_in_generate=True,\n",
    ")\n",
    "generate_time = time.time() - start_generate\n",
    "\n",
    "# Time the decoding part\n",
    "start_decode = time.time()\n",
    "generated_tokens = outputs.sequences[0, inputs.input_ids.shape[1]:]\n",
    "decoded_text = processor.decode(generated_tokens, skip_special_tokens=True)\n",
    "decode_time = time.time() - start_decode\n",
    "\n",
    "# Calculate total time\n",
    "total_time = time.time() - start_total\n",
    "\n",
    "# Print results\n",
    "print(f\"Processing time: {process_time:.4f} seconds\")\n",
    "print(f\"Generation time: {generate_time:.4f} seconds\")\n",
    "print(f\"Decoding time: {decode_time:.4f} seconds\")\n",
    "print(f\"Total time: {total_time:.4f} seconds\")\n",
    "print(\"\\nGenerated text:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55868ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=128,\n",
    "    return_dict_in_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.sequences[0, inputs.input_ids.shape[1]:]\n",
    "decoded_text = processor.decode(output, skip_special_tokens=True)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tokens: {len(tokenized.input_ids[0])}\")\n",
    "\n",
    "for idx, probs in enumerate(router_probs[0:1]):\n",
    "    print(f\"Layer {idx} router probabilities:\")\n",
    "    print(f\"Shape: {probs.shape}\")\n",
    "    print(f\"Top-5 values per token: {torch.topk(probs, 3, dim=-1).values}\")\n",
    "    print(f\"Top-5 indices per token: {torch.topk(probs, 3, dim=-1).indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec2f6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(messages):\n",
    "    start_total = time.time()\n",
    "\n",
    "    # Time the processing part\n",
    "    start_process = time.time()\n",
    "    tokenized = processor.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "    )\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "    process_time = time.time() - start_process\n",
    "\n",
    "    # Time the generation part\n",
    "    start_generate = time.time()\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "    generate_time = time.time() - start_generate\n",
    "\n",
    "# Time the decoding part\n",
    "    start_decode = time.time()\n",
    "    generated_tokens = outputs.sequences[0, inputs.input_ids.shape[1]:]\n",
    "    decoded_text = processor.decode(generated_tokens, skip_special_tokens=True)\n",
    "    decode_time = time.time() - start_decode\n",
    "\n",
    "    # Calculate total time\n",
    "    total_time = time.time() - start_total\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Processing time: {process_time:.4f} seconds\")\n",
    "    print(f\"Generation time: {generate_time:.4f} seconds\")\n",
    "    print(f\"Decoding time: {decode_time:.4f} seconds\")\n",
    "    print(f\"Total time: {total_time:.4f} seconds\")\n",
    "    print(\"\\nGenerated text:\")\n",
    "    print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2075bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://datasets-server.huggingface.co/rows\"\n",
    "params = {\n",
    "    \"dataset\": \"Muennighoff/mbpp\",\n",
    "    \"config\": \"full\",\n",
    "    \"split\": \"test\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 100\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Print the response or parse JSON\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Base API URL\n",
    "base_url = \"https://datasets-server.huggingface.co/rows\"\n",
    "dataset = \"Muennighoff/mbpp\"\n",
    "config = \"full\"\n",
    "length = 100  # Number of rows per page; increase or loop if needed\n",
    "\n",
    "# Function to fetch split data\n",
    "def fetch_split(split, offset=0, length=100):\n",
    "    params = {\n",
    "        \"dataset\": dataset,\n",
    "        \"config\": config,\n",
    "        \"split\": split,\n",
    "        \"offset\": offset,\n",
    "        \"length\": length\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [row[\"row\"] for row in data[\"rows\"]]\n",
    "    else:\n",
    "        print(f\"Error fetching {split} split:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "# Fetch each split\n",
    "train_data = fetch_split(\"train\")\n",
    "validation_data = fetch_split(\"validation\")\n",
    "test_data = fetch_split(\"test\")\n",
    "\n",
    "# Preview a few entries\n",
    "print(\"Train Example:\", train_data[0] if train_data else \"None\")\n",
    "print()\n",
    "print(\"Validation Example:\", validation_data[0] if validation_data else \"None\")\n",
    "print()\n",
    "print(\"Test Example:\", test_data[0] if test_data else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae313f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = test_data[:10]\n",
    "import time\n",
    "for example in subset:\n",
    "    input_text = example[\"text\"]\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": input_text },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    inference(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e610a-9cfb-4050-bac4-ae85c5bacc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tokens: {len(tokenized.input_ids[0])}\")\n",
    "\n",
    "for idx, probs in enumerate(router_probs[0:1]):\n",
    "    print(f\"Layer {idx} router probabilities:\")\n",
    "    print(f\"Shape: {probs.shape}\")\n",
    "    print(f\"Top-3 values per token: {torch.topk(probs, 3, dim=-1).values}\")\n",
    "    print(f\"Top-3 indices per token: {torch.topk(probs, 3, dim=-1).indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7b619-af58-4376-9d5a-c53e4674c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "问：你今天心情怎么样？\n",
    "答：我今天心情很好，准备迎接新的一天。\n",
    "\n",
    "问：你平时喜欢做什么运动？\n",
    "答：我平时喜欢跑步和打篮球。\n",
    "\n",
    "问：你最喜欢的中国菜是什么？\n",
    "答：我最喜欢吃麻婆豆腐，因为它又辣又香。\n",
    "\n",
    "问：你通常几点起床？\n",
    "答：我通常早上七点起床。\n",
    "\n",
    "问：你今天工作／学习的主要任务是什么？\n",
    "答：我今天要完成一个重要的项目演示。\n",
    "\n",
    "问：你喜欢听什么类型的音乐？\n",
    "答：我喜欢听流行音乐和一些轻柔的民谣。\n",
    "\n",
    "问：你下一个假期想去哪里旅行？\n",
    "答：我想去云南看风景和品尝当地美食。\n",
    "\n",
    "问：你有没有养宠物？它叫什么名字？\n",
    "答：我有一只猫，名字叫“小灰”。\n",
    "\n",
    "问：你最喜欢的电影是哪一部？\n",
    "答：我最喜欢《肖申克的救赎》，因为故事很感人。\n",
    "\n",
    "问：你有什么长期目标或者梦想？\n",
    "答：我希望能够环游世界，体验不同的文化。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1b7da-b034-42ef-87bb-0cdab788a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "इनपुट: आप आज कैसा महसूस कर रहे हैं?\n",
    "आउटपुट: मैं आज बहुत अच्छा महसूस कर रहा हूँ, नए दिन का स्वागत करने को तैयार हूँ।\n",
    "\n",
    "इनपुट: आप आम तौर पर कौन सा खेल खेलना पसंद करते हैं?\n",
    "आउटपुट: मुझे आम तौर पर दौड़ना और बास्केटबॉल खेलना पसंद है।\n",
    "\n",
    "इनपुट: आपका पसंदीदा चीनी व्यंजन क्या है?\n",
    "आउटपुट: मेरा पसंदीदा व्यंजन मापो टोफू है, क्योंकि यह तीखा और सुगंधित होता है।\n",
    "\n",
    "इनपुट: आप आम तौर पर कितने बजे उठते हैं?\n",
    "आउटपुट: मैं आम तौर पर सुबह सात बजे उठता हूँ।\n",
    "\n",
    "इनपुट: आज आपके काम/अध्ययन का मुख्य कार्य क्या है?\n",
    "आउटपुट: आज मुझे एक महत्वपूर्ण परियोजना प्रस्तुति पूरी करनी है।\n",
    "\n",
    "इनपुट: आप किस तरह का संगीत सुनना पसंद करते हैं?\n",
    "आउटपुट: मुझे पॉप संगीत और हल्की लोक‑गाने सुनना पसंद है।\n",
    "\n",
    "इनपुट: आप अपनी अगली छुट्टी में कहाँ यात्रा करना चाहेंगे?\n",
    "आउटपुट: मैं युन्नान जाना चाहूँगा, वहाँ का नजारा देखने तथा स्थानीय व्यंजन चखने के लिए।\n",
    "\n",
    "इनपुट: क्या आपके पास कोई पालतू है? उसका नाम क्या है?\n",
    "आउटपुट: मेरे पास एक बिल्ली है, नाम “छोटू” है।\n",
    "\n",
    "इनपुट: आपकी पसंदीदा फिल्म कौन सी है?\n",
    "आउटपुट: मेरी पसंदीदा फिल्म “द शॉशैंक रिडेम्प्शन” है, क्योंकि इसकी कहानी बहुत मार्मिक है।\n",
    "\n",
    "इनपुट: आपके दीर्घकालिक लक्ष्य या सपने क्या हैं?\n",
    "आउटपुट: मैं दुनिया भर की यात्रा करना और विभिन्न संस्कृतियों का अनुभव करना चाहता हूँ।"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
